Hadoop 과 Spark의 차이점
=======================
Hadoop과 Spark는 모두 빅데이터 프레임 워크이다. 하지만 용도에서 다른 차이가 있다.


## Hadoop의 역할및 특징
하둡은 기본적으로 분산형 데이터 인프라스트럭처로써, 대량의 데이터 컬랙션을 사용 서버 클러스터 냐 복수 노드들에 분산시키는 역활을 한다. 맞춤 제작한 하드웨어를 구매하고 유지하는대 들어가는 사용자의 비용 부담을 줄여준다는 장점이 있다. 또한 데이터를 인덱싱하고 추적해 빅데이터 프로세싱 및 애널리틱스 활동의 효율성을 큰 폭으로 개선해주어 많은 시장의 지지를 얻고 있다.


## Spark의 역할및 특징
스파크는 이러한 분산형 데이터 컬랙션 상부에서 동작하는 데이터 프로세싱 툴이며, 분산형 스토리지로서의 역활은 수행하지 않는다. 스파크의 속도는 맵리듀스와 비교해 월등히 뛰어나다. 데이터 프로세싱 방버에 따른 차이이다. 단계별 데이터 처리 방식을 사용하는 맵리듀스와 달리 스파크는 전체 데이터 셋을 한번에 다룬다.


### 워크플로

맵리듀스 : 클러스터에서 데이터를 읽은 뒤, 동작을 실행하고, 결과를 클러스터에 기록한 다음, 또 다시 업데이트된 데이터를 클러스터로 부터 읽어내고 다음 동작을 실행한 후 결과를 클러스터에 입력하는 방식이다.

스파크 : 클러스터로부터 데이터를 읽어 들이고 필요한 모든 애널리틱스 운영을 수행한다. 결과물을 클러스터에 입력하는 전 과정아 동시적으로 진행된다. 즉, 모든 데이터 운영을 메모리 내에서 실시간에 가깝게 처리 할 수 있다.  

__배치 프로세싱으 경우에는 스파크가 맵리듀스 보다 10배 빠른 수행 가능__
__인 메모리 애널리틱스의 경우에는 속도 차이가 100배 난다.__


## Hadoop과 Spark는 상호 독립적이다.
하둡은 하둡 분산형 파일 시스템(HDFS, Hadoop Distributed File System)이라는 이름의 스토리지 컴포넌트와 함께 프로세싱 컴포넌트인 맵리듀스도 제공한다. 즉, 프로세싱 작업을 위해 스파크를 필수적으로 필요로 하지 않다. 반대로 스파크도 하둡 없이 이용할 수 있다. 스파크에 자체 파일 관리 시스템이 포함되진 않고 그것을 필요하지만, 굳이 HDFS가 아니더라도 여타 클라우드 기반 데이터 플랫폼과도 융합될 수 있다. 스파크 자체가 원래 하둡용으로 설계된 솔루션이어서 둘이 함께 사용할 때 가장 좋다.

## 고장 회복 방식은 다르다.
매 운영 이후 결과를 디스크에 기록하는 하둡의 방식의 시스템 사고나 고장 상황에서 매우 유용할 수 있다. 스파크의 경우에는 탄력적 분산형 데이터셋(RDD, Resilient Distributed Dataset)의 형태로 데이터 오브젝트들을 데이터 클러스터 전반에 분산 시킴으로써 탄력성을 보장하고 이 데이터 오브젝트들은 메모리 내에, 혹은 디스크에 저장할 수 있으며, 또 RDD는 사고나 고장이 나더라도 완벽하게 복구할 수 있게 하는 기술이다

검색할 단어들
* 탄력적 분산형 데이터셋(RDD) : 여러 분산 노드에 저장되는 변경이 불가능한 데이터의 집합(객체)으로 각각 RDD는 여러개의 파티션으로 분리된다.(서로 다른 노드에서 분리되어 실행됨) 즉, 스파크 내에 변경이 불가능한 저장된 데이터를 RDD라고 한다. 변경을 하기위해서는 새로운 데이터 셋을  생성해야 한다.


원문보기:
http://www.ciokorea.com/news/27798#csidx027bc6b89aa719fbd95b7c116d8cbd1

Linear Regression(선형회귀)
=================
2차원 좌표에 분포된 데이터를 1차원 직선 방정식을 통해 표현되지 않은 데이터를 예측하기 위한 분석 모델이다. 간단하게 xy축 좌표계에서 직선을 그렸다 생각하면 된다.

## 회귀분석
점들이 퍼져있는 형태에서 패턴을 찾아내고, 이 패턴을 활용해서 무언가를 예측하는 분석이다. 새로운 표본을 뽑았을 때 평균으로 돌아가려는 특징이 있기 때문에 붙은 이름이다.

## Hypothesis (가설)
Hypothesis h는 Feature를 넣으면 Targeted value를 계산해주는 일종의 공식이다. Linear Regression에서 사용하는 1차원 방정식을 가리키는 용어이다. 수식에서는 h(x), H(x)로 표현된다.

H(x) = Wx + b에서 Wx + b는 x에 대한 1차 방정식으로 직선을 표현한다. 기울기인 W(weight)와 절편인 b(bias)가 반복되는 과정에서 계속 바뀌고, 마지막 루프에서 바뀐 최종값을 사용해서 데이터 예측(prediction)에 사용된다. 최종결과로 나온 가설을 모델(model)이라 하며, "학습되었다"라고 한다. 학습된 모델은 배포되어서 새로운 학습을 통해 수정되기 전까지 지속적으로 활용된다.

## Cost (비용)
Hypothesis 방정싱에 대한 Cost(비용)로 방정식의 결과가 크게 나오면 좋지 않다고 얘기하고, 루프를 돌 때마다 W와 b를 비용이 적게 발생하는 방향으로 수정하게 된다. 놀랍게도 미분이라는 수학 공식을 통해 스스로 최저 비용을 찾아가게 된다.

## Cost 함수
Hypothesis 방정식을 포함하는 계산식이다. 현재의 기울기(W)와 절편(b)에 대해 Cost(비용)을 계산해 주는 함수다. 매법 호출할 때마다 반환값으로 표현되는 비용이 줄어들어야 한다. 지금 Linear Regression에서는 최소 비용을 검색하는 역활을 한다.
